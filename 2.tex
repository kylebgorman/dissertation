\chapter{Categorical and gradient aspects of wordlikeness judgements} 
\label{gradience}

Two nonce words, \emph{blick} [blɪk] and \emph{bnick} [bnɪk], underlie the claim that speakers can rapidly distinguish between possible and impossible words \citet{Halle1962}. In \emph{SPE}, \citet{SPE} use a third word, \emph{bnzk}, to argue that nonce words fall on a cline of well-formedness. Neither \emph{bnick} nor \emph{bnzk} are possible words of English, they are possible words in other languages: stop-nasal onsets are found in Moroccan Arabic (e.g., \emph{bniqa} `closet') and stop-nasal-fricative-stop words in Imdlawn Tashlhiyt Berber \citep{Dell1985}. However, there is some sense in which \emph{bnzk} is even less English-like than \emph{bnick}. Of this, \citeauthor{SPE} write:

\begin{quote}
Hence, a real solution to the problem of ``admissibility'' will not simply define a tripartite categorization of occurring, accidental gap, and inadmissible, but will define the `degree of admissibility' of each potential lexical matrix in such a way as to\ldots{}make numerous other distinctions of this sort (\emph{SPE}:416--417)
\end{quote}

\noindent
The position that the well-formedness of nonce words is consistent the view of syntactic grammaticality taken in \emph{LSLT} and \emph{Aspects} \citep{LSLT,ASPECTS}, where it is claimed that different syntactic violations result in different degrees of ungrammaticality.

Most recent discussions of the ``problem of admissibility'' focus on this cline of wellformedness as it is evidenced in wordlikeness tasks.

\begin{quote}
When native speakers are asked to judge made-up (nonce) words, their intuitions are rarely all-or-nothing. In the usual case, novel items fall along a gradient cline of acceptability. \citep[][9]{Albright2009a}

In the particular domain of phonotactics gradient intuitions are pervasive: they have been found in every experiment that allowed participants to rate forms on a scale.
\citep[][382]{Hayes2008a}

\ldots{}when judgements are elicited in a controlled fashion from speakers, they always emerge as gradient, including all intermediate values. \citep[371]{Shademan2006} 
\end{quote}

\begin{quote}
\ldots{}A defect of current grammatical acounts of phonotactics is that they render simple up-or-down decisions concerning well-formedness and cannot account for gradient judgements. \citep[371]{Shademan2006}
\end{quote}

\citet[382]{Hayes2008a} ``consider the ability to model gradient intuitions to be an important criterion for evaluating phonotactic models''.

\begin{quote}
No integer seems to sit on the fence, undecided as to whether it is quite even, or perhaps a bit odd. No odd number seems odder than any other odd number. \citep[274]{Armstrong1983}
\end{quote}

\begin{quote}
Some have responded to these findings very consistently, by asserting that the experimental findings are to be interpreted as before: that, psychologically speaking, odd numbers as well as birds and vegetables are graded concepts\ldots{} We reject this conclusion just because we could not explain how a person could compute with integers who believed that 7 was odder than 23. We assert confidently that the facts about subjects being able to compute and about their being able to give the definition of odd number, etc., are the more important, highly entrenched, facts we want to preserve and explain\ldots{} we ourselves are prepared to give up the seeming fact that some odd numbers appear, as shown by their behavior in certain experimental paradigms, to be odder than others\ldots{}we do not give it up by saying that it was no fact; rather, by saying it must have been a fact about something other than the structure of concepts. \citep[284]{Armstrong1983}
\end{quote}

\begin{quote}
\ldots{}we hold that \emph{fruit} and \emph{odd number} have different structures, and yet we obtain the same experimental outcome for both. But if the same result is achieved regardless of the concept struture, then the experimental design is not pertinent to the determination of concept structure. \citep[284--5]{Armstrong1983}
\end{quote}

At first blush, this would seem to argue against a naïve account of wellformedness judgements in which ill-formedness results when prosodic parsing fails (e.g., \citealt{Ito1989a}, \citealt{Noske1992}, \citealt{OT}). Consider the possibility that a nonce word is ill-formed if it cannot be syllabified without modification. There is a long history for the proposal that impossible words are those whose surface form cannot be parsed into prosodic structures like syllables without further phonological modification (e.g., 

\begin{figure}
\centering
\includegraphics{density.pdf}
\caption{Average ratings of individual nonce words, linearly transformed to fit the interval [0, 1]}
\label{dsn}
\end{figure}

\begin{table}
\centering
\begin{tabular}{l rrr}
\toprule
                        & subjects & items & trials \\
\midrule
\citealt{Albright2007}  & 68       & 40    & 2,720  \\
\citealt{Albright2003a} & 24       & 87    & 2,064  \\
\citealt{Scholes1966}   & 33       & 63    & 2,178  \\
\midrule
\textsc{Total}          & 125      & 187   & 6,962  \\
\bottomrule
\end{tabular}
\caption{Subject and item counts}
\label{counts}
\end{table}

\begin{table}
\centering
\begin{tabular}{l rrrr}
\toprule
Pearson $r$               & \textsc{prosody} & \textsc{maxent} & \textsc{bigram} & \textsc{density} \\
\midrule
\citealt{Albright2007}    & \textbf{.725}    & {.703}          & {.463}          & {.695}           \\
\citealt{Albright2003b}   & {.594}           & {.208}          & \textbf{.746}   & {.688}           \\
\citealt{Scholes1966}     & {.803}           & {.534}          & {.737}          & \textbf{.834}    \\
\midrule
Spearman $\rho$           & \textsc{prosody} & \textsc{maxent} & \textsc{bigram} & \textsc{density} \\
\midrule
\citealt{Albright2007}    & \textbf{.819}    & {.661}          & {.338}          & {.612}           \\
\citealt{Albright2003b}   & {.662}           & {.389}          & {.699}          & \textbf{.739}    \\
\citealt{Scholes1966}     & {.769}           & {.575}          & {.794}          & \textbf{.817}    \\
\midrule
Kendall $\tau_{b}$        & \textsc{prosody} & \textsc{maxent} & \textsc{bigram} & \textsc{density} \\
\midrule
\citealt{Albright2007}    & {.666}           & \textbf{.683}   & {.245}          & {.450}           \\
\citealt{Albright2003b}   & {.474}           & {.159}          & {.499}          & \textbf{.558}    \\
\citealt{Scholes1966}     & {.619}           & {.484}          & {.614}          & \textbf{.671}    \\
\midrule
Goodman-Kruskal $\gamma$  & \textsc{prosody} & \textsc{maxent} & \textsc{bigram} & \textsc{density} \\
\midrule
\citealt{Albright2007}    & \textbf{.874}    & {.849}          & {.502}          & {.574}           \\
\citealt{Albright2003b}   & \textbf{.929}    & {.606}          & {.246}          & {.488}           \\
\citealt{Scholes1966}     & \textbf{.907}    & {.558}          & {.628}          & {.738}           \\
\bottomrule
\end{tabular}
\caption{FIXME}
\label{scores}
\end{table}

%\subsubsection{Maximum entropy phonotactics}
%
%\citeauthor{Hayes2008a} (\citeyear{Hayes2008a}; henceforth H\&W) develop a sophisticated model of phonotactic grammaticality which estimates a probability distribution over phoneme sequences by weighing constraints according to the principle of maximum entropy, following \citet{Goldwater2003} and \citet{Jager2007}. H\&W report that the predictions of their model are closely correlated with the \citet{Scholes1966} wordlikeness ratings. A direct replication of their predictions was attempted by using the software, model parameters, and training data as described in that study. Since the training of the maximum entropy model is inherently stochastic, producing slightly different outcomes on each run, the lowest scoring of ten runs is reported (H\&W:396), though in general there is not a great deal of variation between individual runs. One limitation of this model is that it is not feasible to score whole words, as the number of constraints which must be inspected grows exponentially as the span of possible constraints increases. Following H\&W and of \citet{Albright2009a}, who also applies the maximum entropy model to the \citet{Albright2003b} norms, the model is trained and scored only on stimulus onsets. However, as a consequence, the maximum entropy model performs particularly poorly on this data set, as many stimuli contain phonotactic violations in rime positions.
%
%\subsubsection{Segment bigram probability} 
%\label{bigram}
%
%The bigram probability of a sequence $ijk$ is the product of the probability of an sequence-initial $i$, the probability that $j$ follows $i$, and the probability that $k$ follows $j$, and the product of sequence-final \emph{k}.
%
%\begin{unlabeledexample}
%$\displaystyle \hat{p}(ijk) = p(i|\textrm{start}) \cdot p(j|i) \cdot p(k|j) \cdot p(\textrm{stop}|k)$
%\end{unlabeledexample}
%
%\noindent \citet{Albright2009a} employs bigram probability to model wordlikeness judgements. While the focus of \citeauthor{Albright2009a}'s study is on developing a model which uses bigrams over phonological features rather than segments themselves, \citeauthor{Albright2009a}'s evaluation, which includes both the \citeauthor{Scholes1966} and \citeauthor{Albright2003b} data sets, finds an advantage for segmental bigrams. \citeauthor{Albright2009a} does not provide an implementation of the featural bigram model, nor does his study describe it in sufficient detail to allow for a new implementation, but segmental bigram scores for the \citeauthor{Albright2003a} data are reported in the appendix. As reported by \citeauthor{Albright2009a}, segmental bigrams outperform featural bigrams (see Table \ref{albrightimproved}).
%
%\citeauthor{Albright2009a} estimates bigram probabilities using the method of maximum likelihood over types in the lexicon. The variant of segmental bigrams used here computes probabilities with a simple type of smoothing in which the count of all possible bigrams (including those never observed) are incremented by one. This technique is known as Laplace, or ``add one'' smoothing. This has the desirable effect that no nonce word is ever assigned a zero probability, and produces a small increase in the correlation between the \citeauthor{Albright2003b} wordlikeness norms compared with the maximum likelihood estimate (Table \ref{albrightimproved}). For all three data sets, this model also consistenly outperforms positional probability models defined by \citet{Vitevitch2004} and \citet{Vaden2009}; given that these model scores are highly correlatd with bigram probability \citep[][54]{Vitevitch1997}, they are not considered further. The bigram model consistently performs well in all the evaluations, and has the highest Spearman correlation with the \citeauthor{Greenberg1964} and \citeauthor{Scholes1966} data, and is frequently second place model to the binary baseline elsewhere.
%
%\subsubsection{Neighborhood density} 
%\label{density}
%
%There are now many methods for computing similarity between nonce words and existing words, long thought to be reflected in wordlikeness judgements. 
%For this study, a number of such methods were evaluated, including the Generalized Neighborhood Model \citep{Bailey2001}, PLD20 \citep{Suarez2011}, and a number of variations on neighborhood density \citep{Coltheart1977} provided by \citet{Vaden2009}. The best performance was obtained with the simplest version of neighborhood density, which is defined as the number of real monomorphemic words which can be changed into the target nonce word by a single insertion, deletion, or substitution of a phone.\footnote{\citet{Greenberg1964} use a variant in which only substitutions are counted.} For instance, the neighbors of \emph{blick} include \emph{blink} (insertion), \emph{lick} (deletion) and \emph{black} (substitution). While many studies \citep[e.g.,][]{Bailey2001} report robust lexical similarity effects, it may be that the relatively weak performance of neighborhood density is the result of the presence of gross phonotactic violations.
%
%\subsection{Modeling residual gradience}
%
%The primary result is that no gradient model reliably exceeds the accuracy of the binary baseline. Despite this, there are relatively strong correlations between the binary baseline and these gradient models (see Table \ref{bcor}). From the strong performance of the categorical model one can infer that the gradient models do not reliably predict intermediate ratings, or contrasts in ratings between words which are grouped together. To quantify this, the following method was used to estimate the residual contribution of the three gradient models once gross phonotactic violations are taken into account. Instead of calculating rank correlations directly on the model scores as in Table \ref{cor}, the model scores are mapped to ranks with the additional constraint that all ``valid'' stimuli be ranked above all ``invalid'' stimuli. The resulting ranks are used to compute new correlation statistics. Finally, the binary baseline correlation is subtracted from this number, so that the resulting value is the amount of improvement derived from augmenting the binary model with gradience. These difference numbers are shown in Table \ref{controlled}. In most cases, including the gradient models on top of the binary baseline produces a worse correlation than is obtained with the binary baseline alone.
%
%For $\tau_b$ and $\gamma$, the interpretation of this result is clear. The gradient models assign rankings to the sets of phonotactically valid and invalid clusters, respectively. For instance, the bigram model favors \emph{troog} [tɹuːɡ] over \emph{swach} [swætʃ], though neither contains any gross phonotactic violation. Similarly, the bigram model favors \emph{chwoop} [tʃwuːp] over \emph{zhrick} [ʒɹɪk], even though both contain ill-formed onsets. However, the majority of such predicted contrasts are not reflected in speakers' judgements; for instance, \emph{troog} is rated less English-like than \emph{swach} \citep{Greenberg1964}, contrary to the model predictions. This shows quite starkly that these models fail to reliably predict intermediate ratings.
%
%\subsection{The gradience hypothesis}
%
%This chapter has evaluated the axiom of gradience as a falsifiable alternative hypothesis. The surprising result is that virtually all of the apparent coverage of state-of-the-art gradient phonotactic models is simply a reflection of their ability to distinguish between the possible and the totally impossible; beyond this, they are unreliable. A trivial baseline, endowed with few abilities to project beyond the observed data, generally outperforms the state of the art. The projections made by the state-of-the-art gradient models are not like those made by speakers. It remains to be seen is whether any model can be put forth which accurately predicts these intermediate ratings.
%
%These result provide support for recent findings that speakers asked to perform gradient syntactic judgements produce responses closely corresponding to a widely recognized categorical grammatical/ungrammatical distinction \citep{Sprouse2007}.
%
%\subsection{Extensions to the binary baseline}
%
%The strong performance of the binary baseline should not be taken as evidence either that wordlikenesss judgements are binary, or that the binary baseline is a plausible model. The most serious limitation of this evaluation is the primitive nature of the binary baseline. The inability to generalization within onsets and rimes is a serious flaw, as is the assumption of independence of onset and rime. Regarding the rime, \citet{Borowsky1989} proposes a theory of possible rimes in English, which does make the correct prediction regarding the unattested but well-formed [ɛsp]. On the other hand, a cognitively plausible version of this model might need to entertain phonotactic generalizations that are larger than these units, since syllable-sized phonotactic generalizations have been proposed for English \citep[e.g.,][]{Berkley1994a,Berkley1994b,Coetzee2008b,Fudge1969}. 
%
%A possible further extension to the binary baseline would be the introduction of additional levels of wellformedness. While the evaluation has shown that current gradient models do not reliably identify intermediate wellformedness, it does seem possible to identify at least three levels of grammaticality: for instance, one might encode the intuition that \emph{zhlick} [ʒlɪk] is more English-like than \emph{bnick}, though both have unattested onsets. There are precedents for labeling certain attested words as phonotactically ``peripheral'' (see, e.g., the appendices in \citealt{Myers1987} and \citealt{Borowsky1989}); such words are regarded as lexical exceptions to language-general principles of syllabification. If this extends to nonce words, then an intermediate level of grammaticality could be assigned to ``possible'' but formally marked words. Another likely source of additional levels of grammaticality is the cumulative effect of multiple phonotactic violations. While, as \citet{Coleman1997} note, classical Optimality Theory predicts that a nonce word is as ill-formed as its worst deviation from syllable structure, it is possible to imagine that multiple phonotactic violations would result in greater degrees of ill-formedness. The bigram and maxent models make this prediction, as do many others \citep[e.g.,][]{Legendre1990,Levelt2000,Albright2008,Anttila2008a,Pater2009b} but despite this, there is still little data demonstrating cumulative effects in wordlikeness tasks.
%
%\subsection{Language acquisition}
%
%The weak empirical status of gradient phonotactic knowledge as reflected in adults has rammifications for language acquisition under the hypothesis that that infants acquiring language deploy the same representations as adults \citep[e.g.,][]{Macnamara1982,Pinker1984,Crain1991,Carey1995,deVilliers2001,Legate2007}. Gradient wordlikeness judgements in adults would provide support for claims that infants recognize statistical(inherently gradient) dependencies between segments \citep{Jusczyk1994} and use these to segment words \citep{Saffran1996}. An emerging consensus suggests, however, that infants attend to transitional probabilities primarily in the absence of grammatical cues \citep{Gambell2005,Hohne1994,Johnson2001,Jusczyk1999c,Lignos2012b,Mattys2001a,Shukla2007,Lew-Williams2012}. The vacuous nature of current evidence for gradient phonotactic knowledge in adults further weakens any hypothesis that would link statistical learning in infants to adults' behaviors.
%
%\section{Conclusion}
%
%%For instance, infants as young as 4.5 months seem to be aware that English nasal codas agree in place with following obstruents \citep{Mattys2001b,Jusczyk2002,Davidson2004}. 
%%It might be the case that syllable co-occurrence statistics might be little more than a reflection of infants' learning of categorical ``lexical viability'' constraints \citep{Johnson2003} of the sort also seen in adult speech processing \citep[e.g.,][]{Norris1997}. 
%
%% other ratings, but por qué?:
%% 
%% Hayes2000
%% 
%% Albright2003a
%% Albright2003b
%% Prasada1993 
%% 
%% Bard1996
%% 
%% Koo2009
%% 
%% Treiman2000
%% 
%% Warker2006
%% 
%% Massaro1983
%% 
%% Rusaw2009
%do not explicitly state why this data is relevant to the construction of models of wordlikeness. Presumably, these authors believe that these patterns of judgements demonstrate that wordlikeness, as an internal state, is gradient simply because subjects make use of intermediate degrees of wordlikeness in judgement tasks. This proposition, generalized below, is ``naïve'' not because it lacks sophistication, but because it is rooted in a belief in naïve realism, a philosophy which holds that perception provides a relatively direct picture of the nature of the world, an influential view in the cognitive sciences in general (see \citealt{Fodor1981a} for a critique).
%
%\citeauthor{Chomsky1965} were not the first to consider the notion of possible and impossible words. Their primary contribution is that their mentalist perspective: they recognize that naïve speakers effortlessly acquire language-specific generalizations about possible and impossible words and can report them without any explicit training.
%
%However, not all early literature is concerned with gradience. \citet[31]{Vogt1954}, for instance, recognizes that the taxonomic phoneme is insufficient to account for many wordlikeness contrasts. \citeauthor{Vogt1954} observes that allophony may account for the absence of certain phone sequences, but it does not provide a suitable explanation for the absence of initial [bn] in English, nor does it make correct predictions about the surface realization of an underlying initial /bn/. \citeauthor{Vogt1954} concludes that additional grammatical machinery will be needed to account for possible and impossible words. 
%
%Most relevant to the question at hand, \citet{Frisch2000} and \citet{Vitevitch1997} find that speakers' wordlikeness ratings of multisyllabic words are correlated wtih the positional probailities of the constituent syllables. Unfortunately, none of these researchers make any effort to eliminate the possibility that the low positional probability stimuli are ``impossible'' words of English. In fact, 
%Chapter \ref{clusters} argues
%%the author has argued elsewhere \citep{Gorman2012c}
%that many of the stimuli used by \citeauthor{Frisch2000} and \citeauthor{Vitevitch1997} contain illicit word-medial consonant clusters. While \citeauthor{Vitevitch1997} neither control nor manipulate the well-formedness of medial clusters, in a post-hoc test they consider a probabilistic measure of cluster well-formedness, which reveals that cluster well-formedness is correlated with syllable-internal positional probabilities and wordlikeness judgements, but \citeauthor{Vitevitch1997} ultimately conclude this cannot explain all the variation in wordlikeness. 
%
%Using the head-term preference paradigm, \citet{Jusczyk1993b} and \citet{Friederici1993} find that typically-developing children as young as 9 months of age distinguish between nonce words which are and are not phonotactically valid in their target language. \citet{Jusczyk1994} report that 9-month-old children acquiring English also show preferences for nonce words with high positional probability over those with low positional probability. Faciliatory effects of positional probability (i.e., shorter latencies) are reported for other nonce word tasks conducted with adults, including single-word shadowing \citep{Vitevitch1997,Vitevitch1998}, same/different judgements \citep{Vitevitch1999a,Luce2001,Lipinski2005,Vitevitch2005}, and lexical decision \citep{Pylkkanen2002a}.
%
%The aforementioned studies all conclude that the gradient measure of positional probability correlates with behavioral results. As the flaws of the \citet{Vitevitch1997} study demonstrate, the aforementioned studies do little to tease apart the gradient and categorical aspects of phonotactics. More generally, they do little to distinguish between positional probability and closely correlated measures like bigram probability (see \S\ref{bigram} below) or neighborhood density, since these studies carefully select stimuli which either have high or low values for all of positional probability, bigram probablility, and neighborhood density. This is particularly troublesome given that no justification has ever been given for the positional probability measure in the first place; it appears to have been created \emph{ex nihilo}; in contrast, the effects of neighborhood density in various psycholinguistic tasks are emergent properties of many models of speech production \citep[e.g.,][]{Luce1998,Luce2000} and perception \citep{Marslen-Wilson1984,Marslen-Wilson1987,McClelland1986,Norris1994,Norris2000}. 
%\subsubsection{\citealt{Greenberg1964}}
%
%\citet{Greenberg1964} investigated wordlikeness using the technique of free magnitude estimation, a mechanism which has become increasingly popular among syntacticians \citep[e.g.,][]{Bard1996}. At the beginning of the experiment, the subject heard a recording of the word \emph{stick}. In subsequent trials, the subjects heard a nonce word and were asked to report ``how far would you say that is from English?'', with \emph{stick} at ``1''; subjects are told that a word that is ``twice as far from English'' as \emph{stick} should be scored ``2''. The data used here are from \citeauthor{Greenberg1964}'s Experiment B, in which 17 undergraduates were presented 17 stimuli in all. In addition to \emph{stick}, the stimuli include three other English words; these four items were excluded from further analyses, leaving 13 stimuli. As is standard practice in psychophysics \citep[e.g.,][]{Butler1987}, magnitudes were log-transformed prior to analysis.
%
